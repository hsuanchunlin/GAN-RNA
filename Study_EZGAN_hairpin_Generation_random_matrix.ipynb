{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Study_EZGAN-hairpin-Generation_random_matrix.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW-zRBArawo4",
        "colab_type": "text"
      },
      "source": [
        "# Study the Generative Model (GAN) for miRNA hairpin in Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl5I25p3a1-A",
        "colab_type": "text"
      },
      "source": [
        "## Prepare the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAw4BPe5av_f",
        "colab_type": "code",
        "outputId": "e4589ce4-8849-4849-baee-9ef3ff4699ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "\n",
        "from IPython import display\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4U6hn5WbV8y",
        "colab_type": "text"
      },
      "source": [
        "## Load the dataset\n",
        "Here we use RNA data as our first practice. In miRNA hairpin database, most of the hairpin lengths are 60nt. Therefore we only take sequences which lengths are 60nt to do the training. For each sequence, the matrix is [[0,0,1,0,0]] which represent the [A,C,G,U,N] matrix. N means if the RNA has label than A, C, G, U, it will be labeled N."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W3d4-6ibTGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = glob.glob('/content/drive/My Drive/Colab Notebooks/*')\n",
        "\n",
        "train_RNA = np.load('/content/drive/My Drive/Colab Notebooks/table_hairpin60_s.npy')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Sc6-3lEwsZB",
        "colab_type": "text"
      },
      "source": [
        "Now we can see the shape of RNA is 44455 sequence, with 60 nts and each length has 5 types of nucleotides."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLexMNZ9-Lol",
        "colab_type": "code",
        "outputId": "a67a9fdc-4955-4632-b287-fa9d13d34906",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_RNA.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44455, 60, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8GHeh47P5Kh",
        "colab_type": "code",
        "outputId": "750159aa-bd9b-42bc-9155-a5d5b578c956",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_RNA[1]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 0, 1, 0],\n",
              "       [0, 1, 0, 0],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 1, 0, 0],\n",
              "       [0, 1, 0, 0],\n",
              "       [0, 0, 1, 0],\n",
              "       [0, 0, 1, 0],\n",
              "       [0, 1, 0, 0],\n",
              "       [0, 1, 0, 0],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 0, 1, 0],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 1, 0, 0],\n",
              "       [0, 1, 0, 0],\n",
              "       [0, 1, 0, 0],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 0, 1, 0],\n",
              "       [1, 0, 0, 0],\n",
              "       [0, 0, 1, 0],\n",
              "       [1, 0, 0, 0],\n",
              "       [0, 1, 0, 0],\n",
              "       [0, 1, 0, 0],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 1, 0, 0],\n",
              "       [1, 0, 0, 0],\n",
              "       [1, 0, 0, 0],\n",
              "       [0, 0, 1, 0],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 0, 1, 0],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 0, 1, 0],\n",
              "       [1, 0, 0, 0],\n",
              "       [0, 0, 1, 0],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 0, 1, 0],\n",
              "       [0, 0, 0, 1],\n",
              "       [1, 0, 0, 0],\n",
              "       [0, 1, 0, 0],\n",
              "       [0, 0, 0, 1],\n",
              "       [1, 0, 0, 0],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 0, 1, 0],\n",
              "       [1, 0, 0, 0],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 0, 1, 0],\n",
              "       [0, 1, 0, 0],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 1, 0, 0],\n",
              "       [1, 0, 0, 0],\n",
              "       [0, 1, 0, 0],\n",
              "       [1, 0, 0, 0],\n",
              "       [0, 1, 0, 0],\n",
              "       [0, 1, 0, 0],\n",
              "       [0, 0, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yskv9foiboeL",
        "colab_type": "text"
      },
      "source": [
        "To feed the matrix to our model, we need to add one depth to train our model and change the type to float32. After reshape and change the type we need to normalize the images to the value between (-1,1)\n",
        "Because the grayscale is 0-255, we will substract 127.5 which is (255/2) and divide them by 127.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDNNIfCqbnqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_RNA = train_RNA.reshape(train_RNA.shape[0], 60, 5, 1).astype('float32')\n",
        "train_RNA = train_RNA.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_1cWzjXNmAx",
        "colab_type": "code",
        "outputId": "bd4d7ab2-be3f-4989-a874-2dce8ccfc52e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "train_RNA.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44455, 60, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuxSbmyenkrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 5000\n",
        "BATCH_SIZE = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaJmEv4znm3-",
        "colab_type": "text"
      },
      "source": [
        "### Use tf.data to create batches and shuffle the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dblBdF5PnlLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_RNA).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRHzV_uDcy7R",
        "colab_type": "text"
      },
      "source": [
        "## Create the model\n",
        "We will use tf.keras.Sequential API to construct our model\n",
        "\n",
        "###The Generator Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux6Mk1JAcQWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_generator_model():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Flatten(input_shape=(240,)))\n",
        "  model.add(tf.keras.layers.Dense(4*60, activation=tf.nn.relu))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  model.add(tf.keras.layers.Dense(200, activation=tf.nn.relu))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  model.add(tf.keras.layers.Dense(4*60, activation=tf.nn.relu))\n",
        "  model.add(tf.keras.layers.Reshape((60,4)))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sScsGwhegIQN",
        "colab_type": "text"
      },
      "source": [
        "##The Discriminator model\n",
        "\n",
        "The discriminator is responsible for distinguishing fake images from real images. It's similar to a regular CNN-based image classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p9hvrzKgD0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Flatten(input_shape=(60, 4)))\n",
        "    model.add(tf.keras.layers.Dense(240, activation=tf.nn.relu))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(120, activation=tf.nn.relu))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(60, activation=tf.nn.relu))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(1, activation=tf.nn.softmax))     \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_46Ne_HgblR",
        "colab_type": "text"
      },
      "source": [
        "##Define the loss functions and the optimizer\n",
        "\n",
        "Let's define the loss functions and the optimizers for the generator and the discriminator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEaxvlHugm0G",
        "colab_type": "text"
      },
      "source": [
        "###Generator loss¶\n",
        "The generator loss is a sigmoid cross entropy loss of the generated RNA matrix and an array of ones, since the generator is trying to generate fake RNAs that resemble the real RNAs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82CAHHbrgaRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_loss(generated_output):\n",
        "    return tf.losses.sigmoid_cross_entropy(tf.ones_like(generated_output), generated_output)\n",
        "  #Study the function tf.ones_like()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahy39uDHg2vB",
        "colab_type": "text"
      },
      "source": [
        "### Discriminator loss\n",
        "The discriminator loss function takes two inputs: real RNA, and generated RNAs. Here is how to calculate the discriminator loss:\n",
        "\n",
        "Calculate real_loss which is a sigmoid cross entropy loss of the real RNAs and an array of ones (since these are the real RNAs).\n",
        "Calculate generated_loss which is a sigmoid cross entropy loss of the generated RNAs and an array of zeros (since these are the fake RNAs).\n",
        "Calculate the total_loss as the sum of real_loss and generated_loss.\n",
        "\n",
        "$$\n",
        "Total loss = real loss + generate loss\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjP4rdUGhQif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(real_output, generated_output):\n",
        "    # [1,1,...,1] with real output since it is true and we want our generated examples to look like it\n",
        "    real_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.ones_like(real_output), logits=real_output)\n",
        "\n",
        "    # [0,0,...,0] with generated images since they are fake\n",
        "    generated_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.zeros_like(generated_output), logits=generated_output)\n",
        "\n",
        "    total_loss = real_loss + generated_loss\n",
        "\n",
        "    return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-K-DdvchSb_",
        "colab_type": "text"
      },
      "source": [
        "### Setting the optimizers\n",
        "The discriminator and the generator optimizers are different since we will train two networks separately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymNk3P6khjEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.train.AdamOptimizer(1e-4)\n",
        "discriminator_optimizer = tf.train.AdamOptimizer(1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WolF4CPfoBWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1h4dQVOWi5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz3QNwa1hsfa",
        "colab_type": "text"
      },
      "source": [
        "## Set GAN for Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI3ttFrGhrBi",
        "colab_type": "code",
        "outputId": "8ec2236d-1134-490c-d11a-fe33ec16ebb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "EPOCHS = 50\n",
        "noise_dim = 240 #create some noize\n",
        "num_examples_to_generate = 5\n",
        "\n",
        "def generate_random_vector(noise_dim, num_examples_to_generate):\n",
        "  #In the tutorial, we will re-use this random vector used to seed the generator\n",
        "  # it will be easier to see the improvement over time\n",
        "  random_vec = []\n",
        "  for i in range(num_examples_to_generate):\n",
        "    for j in range(60):\n",
        "      zero_matrix = [0,0,0,0]\n",
        "      loc = random.randint(0,3)\n",
        "      zero_matrix[loc] = 1\n",
        "      random_vec.append(zero_matrix)\n",
        "  random_vector_for_generation = tf.convert_to_tensor(np.array(random_vec),\n",
        "                                                      dtype=tf.float32)\n",
        "  random_vector_for_generation = tf.reshape(random_vector_for_generation,(num_examples_to_generate,noise_dim))\n",
        "  return random_vector_for_generation\n",
        "\n",
        "random_vector_for_generation = generate_random_vector(noise_dim, num_examples_to_generate)\n",
        "#random_vector_for_generation = abs(tf.random_normal([num_examples_to_generate,\n",
        "#                                                 noise_dim]))\n",
        "random_vector_for_generation.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(5), Dimension(240)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DswgB4kzie6r",
        "colab_type": "text"
      },
      "source": [
        "### Define training method\n",
        "We start by iterating over the dataset. The generator is given a random vector as an input which is processed to output an RNA looking like a real miRNA. The discriminator is then shown the real miRNA sequence as well as the generated sequence.\n",
        "\n",
        "Next, we calculate the generator and the discriminator loss. Then, we calculate the gradients of loss with respect to both the generator and the discriminator variables.\n",
        "\n",
        "### Review\n",
        "tf.GradientTape()\n",
        "generator()\n",
        "discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brnaVOduioj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(images):\n",
        "   # generating noise from a normal distribution\n",
        "      noise = tf.random_normal([BATCH_SIZE, noise_dim])\n",
        "      \n",
        "      with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "      \n",
        "        real_output = discriminator(images, training=True)\n",
        "        generated_output = discriminator(generated_images, training=True)\n",
        "         \n",
        "        gen_loss = generator_loss(generated_output)\n",
        "        disc_loss = discriminator_loss(real_output, generated_output)\n",
        "        \n",
        "      gradients_of_generator = gen_tape.gradient(gen_loss, generator.variables)\n",
        "      gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.variables)\n",
        "      \n",
        "      generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.variables))\n",
        "      discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXz9OnLVjgqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset, epochs):  \n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    print('Start epoch {}'.format(epoch))\n",
        "    for images in dataset:\n",
        "      train_step(images)\n",
        "    #display.clear_output(wait=True)\n",
        "    \n",
        "    # saving (checkpoint) the model every 15 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "      #  checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "      generate_and_save_RNA(generator,epochs,random_vector_for_generation)\n",
        "      \n",
        "    \n",
        "    print ('Time taken for epoch {} is {} sec'.format(epoch + 1,\n",
        "                                                      time.time()-start))\n",
        "    \n",
        "  # generating after the final epoch\n",
        "  #display.clear_output(wait=True)\n",
        " # generate_and_save_RNA(generator,\n",
        " #                          epochs,\n",
        " #                          random_vector_for_generation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvGroteLkLVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_and_save_RNA(model, epoch, test_input):\n",
        "  # make sure the training parameter is set to False because we\n",
        "  # don't want to train the batchnorm layer when doing inference.\n",
        "  predictions = model(test_input, training=False)\n",
        "  predictions = tf.keras.backend.eval(predictions)\n",
        "  predictions = np.array(predictions)\n",
        "  sequence = np.array(['A','C','G','U'])\n",
        "  \n",
        "  for number in predictions:\n",
        "    seq = ''\n",
        "    for list_label in number:\n",
        "      result = np.where(list_label == np.amax(list_label))\n",
        "      seq = seq + sequence[result][0]\n",
        "    print(seq)\n",
        "  #print(predictions[0])\n",
        "  #print(np.shape(predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NbBoBmMZ9iX",
        "colab_type": "code",
        "outputId": "3c2ee7a4-2087-4e1e-812e-d8de6c68465f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " \n",
        "sequence = np.array(['A','C','G','U','N'])\n",
        "test = [[0,0,0,1,0], [0,1,0,0,0]]\n",
        "test2 = np.array(test)\n",
        "seq = ''\n",
        "for list_label in test2:\n",
        "  result = np.where(list_label == np.amax(list_label))\n",
        "  seq = seq + sequence[result][0]\n",
        "seq"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'UC'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_18JzctQgKdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I00aI_LRkT8W",
        "colab_type": "text"
      },
      "source": [
        "## Now let's do the training\n",
        "We will call the training step to do the training.\n",
        "According to my experiment, the training completed in the first few steps. I will find other algorithms to improve the algorithms in the future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI_SV5YJnUDq",
        "colab_type": "code",
        "outputId": "b3395e7d-70bb-419b-db2b-9a3a97baa0b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "train(train_dataset, EPOCHS)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0731 22:11:35.757817 140134306776960 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for epoch 1 is 8.315684795379639 sec\n",
            "Start epoch 1\n",
            "Time taken for epoch 2 is 7.516160011291504 sec\n",
            "Start epoch 2\n",
            "Time taken for epoch 3 is 7.521599054336548 sec\n",
            "Start epoch 3\n",
            "Time taken for epoch 4 is 7.476722240447998 sec\n",
            "Start epoch 4\n",
            "UUGAGCAGCAAUGGUGCAGCUAGCCAAUUAAUUGGACCCACACGGGCAUGGAAGGCGCGA\n",
            "UGGCUCAGAAUUAGACCAAGGAUCCACAUGGUAAAAACCCAUCCAUGAUAUAAAACUGGA\n",
            "CAACGUAGAAAGGGAGCUGGGAGACCAACGACUUGUCUGAACCCUGCAUGUCAGACCGCG\n",
            "CCGAGCAGCAACGGUGCACCAUUCCUGAUAUCCAGACUCUUGGAGGCAAGUUAAAUAAGG\n",
            "UUACGCGCCGUGUUUGGAGUAAUUAAAAAAAAUAAACCGUACCGCGCAUAUCCGGUUAAU\n",
            "Time taken for epoch 5 is 7.42682671546936 sec\n",
            "Start epoch 5\n",
            "Time taken for epoch 6 is 7.432483196258545 sec\n",
            "Start epoch 6\n",
            "Time taken for epoch 7 is 7.506712436676025 sec\n",
            "Start epoch 7\n",
            "Time taken for epoch 8 is 7.396493434906006 sec\n",
            "Start epoch 8\n",
            "Time taken for epoch 9 is 7.52196192741394 sec\n",
            "Start epoch 9\n",
            "UUGAGCAGCAAUGGUGCAGCUAGCCAAUUAAUUGGACCCACACGGGCAUGGAAGGCGCGA\n",
            "UGGCUCAGAAUUAGACCAAGGAUCCACAUGGUAAAAACCCAUCCAUGAUAUAAAACUGGA\n",
            "CAACGUAGAAAGGGAGCUGGGAGACCAACGACUUGUCUGAACCCUGCAUGUCAGACCGCG\n",
            "CCGAGCAGCAACGGUGCACCAUUCCUGAUAUCCAGACUCUUGGAGGCAAGUUAAAUAAGG\n",
            "UUACGCGCCGUGUUUGGAGUAAUUAAAAAAAAUAAACCGUACCGCGCAUAUCCGGUUAAU\n",
            "Time taken for epoch 10 is 7.452761888504028 sec\n",
            "Start epoch 10\n",
            "Time taken for epoch 11 is 7.4851508140563965 sec\n",
            "Start epoch 11\n",
            "Time taken for epoch 12 is 7.388245582580566 sec\n",
            "Start epoch 12\n",
            "Time taken for epoch 13 is 7.381293058395386 sec\n",
            "Start epoch 13\n",
            "Time taken for epoch 14 is 7.350529670715332 sec\n",
            "Start epoch 14\n",
            "UUGAGCAGCAAUGGUGCAGCUAGCCAAUUAAUUGGACCCACACGGGCAUGGAAGGCGCGA\n",
            "UGGCUCAGAAUUAGACCAAGGAUCCACAUGGUAAAAACCCAUCCAUGAUAUAAAACUGGA\n",
            "CAACGUAGAAAGGGAGCUGGGAGACCAACGACUUGUCUGAACCCUGCAUGUCAGACCGCG\n",
            "CCGAGCAGCAACGGUGCACCAUUCCUGAUAUCCAGACUCUUGGAGGCAAGUUAAAUAAGG\n",
            "UUACGCGCCGUGUUUGGAGUAAUUAAAAAAAAUAAACCGUACCGCGCAUAUCCGGUUAAU\n",
            "Time taken for epoch 15 is 7.423168897628784 sec\n",
            "Start epoch 15\n",
            "Time taken for epoch 16 is 7.320648670196533 sec\n",
            "Start epoch 16\n",
            "Time taken for epoch 17 is 7.321608781814575 sec\n",
            "Start epoch 17\n",
            "Time taken for epoch 18 is 7.347409963607788 sec\n",
            "Start epoch 18\n",
            "Time taken for epoch 19 is 7.455691576004028 sec\n",
            "Start epoch 19\n",
            "UUGAGCAGCAAUGGUGCAGCUAGCCAAUUAAUUGGACCCACACGGGCAUGGAAGGCGCGA\n",
            "UGGCUCAGAAUUAGACCAAGGAUCCACAUGGUAAAAACCCAUCCAUGAUAUAAAACUGGA\n",
            "CAACGUAGAAAGGGAGCUGGGAGACCAACGACUUGUCUGAACCCUGCAUGUCAGACCGCG\n",
            "CCGAGCAGCAACGGUGCACCAUUCCUGAUAUCCAGACUCUUGGAGGCAAGUUAAAUAAGG\n",
            "UUACGCGCCGUGUUUGGAGUAAUUAAAAAAAAUAAACCGUACCGCGCAUAUCCGGUUAAU\n",
            "Time taken for epoch 20 is 7.520286560058594 sec\n",
            "Start epoch 20\n",
            "Time taken for epoch 21 is 7.339416265487671 sec\n",
            "Start epoch 21\n",
            "Time taken for epoch 22 is 7.303185939788818 sec\n",
            "Start epoch 22\n",
            "Time taken for epoch 23 is 7.374986886978149 sec\n",
            "Start epoch 23\n",
            "Time taken for epoch 24 is 7.3214733600616455 sec\n",
            "Start epoch 24\n",
            "UUGAGCAGCAAUGGUGCAGCUAGCCAAUUAAUUGGACCCACACGGGCAUGGAAGGCGCGA\n",
            "UGGCUCAGAAUUAGACCAAGGAUCCACAUGGUAAAAACCCAUCCAUGAUAUAAAACUGGA\n",
            "CAACGUAGAAAGGGAGCUGGGAGACCAACGACUUGUCUGAACCCUGCAUGUCAGACCGCG\n",
            "CCGAGCAGCAACGGUGCACCAUUCCUGAUAUCCAGACUCUUGGAGGCAAGUUAAAUAAGG\n",
            "UUACGCGCCGUGUUUGGAGUAAUUAAAAAAAAUAAACCGUACCGCGCAUAUCCGGUUAAU\n",
            "Time taken for epoch 25 is 7.336636781692505 sec\n",
            "Start epoch 25\n",
            "Time taken for epoch 26 is 7.348607778549194 sec\n",
            "Start epoch 26\n",
            "Time taken for epoch 27 is 7.325958490371704 sec\n",
            "Start epoch 27\n",
            "Time taken for epoch 28 is 7.486872911453247 sec\n",
            "Start epoch 28\n",
            "Time taken for epoch 29 is 7.343486309051514 sec\n",
            "Start epoch 29\n",
            "UUGAGCAGCAAUGGUGCAGCUAGCCAAUUAAUUGGACCCACACGGGCAUGGAAGGCGCGA\n",
            "UGGCUCAGAAUUAGACCAAGGAUCCACAUGGUAAAAACCCAUCCAUGAUAUAAAACUGGA\n",
            "CAACGUAGAAAGGGAGCUGGGAGACCAACGACUUGUCUGAACCCUGCAUGUCAGACCGCG\n",
            "CCGAGCAGCAACGGUGCACCAUUCCUGAUAUCCAGACUCUUGGAGGCAAGUUAAAUAAGG\n",
            "UUACGCGCCGUGUUUGGAGUAAUUAAAAAAAAUAAACCGUACCGCGCAUAUCCGGUUAAU\n",
            "Time taken for epoch 30 is 7.523236036300659 sec\n",
            "Start epoch 30\n",
            "Time taken for epoch 31 is 7.743541240692139 sec\n",
            "Start epoch 31\n",
            "Time taken for epoch 32 is 8.043071031570435 sec\n",
            "Start epoch 32\n",
            "Time taken for epoch 33 is 8.00435209274292 sec\n",
            "Start epoch 33\n",
            "Time taken for epoch 34 is 7.360743284225464 sec\n",
            "Start epoch 34\n",
            "UUGAGCAGCAAUGGUGCAGCUAGCCAAUUAAUUGGACCCACACGGGCAUGGAAGGCGCGA\n",
            "UGGCUCAGAAUUAGACCAAGGAUCCACAUGGUAAAAACCCAUCCAUGAUAUAAAACUGGA\n",
            "CAACGUAGAAAGGGAGCUGGGAGACCAACGACUUGUCUGAACCCUGCAUGUCAGACCGCG\n",
            "CCGAGCAGCAACGGUGCACCAUUCCUGAUAUCCAGACUCUUGGAGGCAAGUUAAAUAAGG\n",
            "UUACGCGCCGUGUUUGGAGUAAUUAAAAAAAAUAAACCGUACCGCGCAUAUCCGGUUAAU\n",
            "Time taken for epoch 35 is 7.365503549575806 sec\n",
            "Start epoch 35\n",
            "Time taken for epoch 36 is 7.434985637664795 sec\n",
            "Start epoch 36\n",
            "Time taken for epoch 37 is 7.316659212112427 sec\n",
            "Start epoch 37\n",
            "Time taken for epoch 38 is 7.311958074569702 sec\n",
            "Start epoch 38\n",
            "Time taken for epoch 39 is 7.347097158432007 sec\n",
            "Start epoch 39\n",
            "UUGAGCAGCAAUGGUGCAGCUAGCCAAUUAAUUGGACCCACACGGGCAUGGAAGGCGCGA\n",
            "UGGCUCAGAAUUAGACCAAGGAUCCACAUGGUAAAAACCCAUCCAUGAUAUAAAACUGGA\n",
            "CAACGUAGAAAGGGAGCUGGGAGACCAACGACUUGUCUGAACCCUGCAUGUCAGACCGCG\n",
            "CCGAGCAGCAACGGUGCACCAUUCCUGAUAUCCAGACUCUUGGAGGCAAGUUAAAUAAGG\n",
            "UUACGCGCCGUGUUUGGAGUAAUUAAAAAAAAUAAACCGUACCGCGCAUAUCCGGUUAAU\n",
            "Time taken for epoch 40 is 7.395875692367554 sec\n",
            "Start epoch 40\n",
            "Time taken for epoch 41 is 7.448455572128296 sec\n",
            "Start epoch 41\n",
            "Time taken for epoch 42 is 7.396491765975952 sec\n",
            "Start epoch 42\n",
            "Time taken for epoch 43 is 7.363044261932373 sec\n",
            "Start epoch 43\n",
            "Time taken for epoch 44 is 7.361279249191284 sec\n",
            "Start epoch 44\n",
            "UUGAGCAGCAAUGGUGCAGCUAGCCAAUUAAUUGGACCCACACGGGCAUGGAAGGCGCGA\n",
            "UGGCUCAGAAUUAGACCAAGGAUCCACAUGGUAAAAACCCAUCCAUGAUAUAAAACUGGA\n",
            "CAACGUAGAAAGGGAGCUGGGAGACCAACGACUUGUCUGAACCCUGCAUGUCAGACCGCG\n",
            "CCGAGCAGCAACGGUGCACCAUUCCUGAUAUCCAGACUCUUGGAGGCAAGUUAAAUAAGG\n",
            "UUACGCGCCGUGUUUGGAGUAAUUAAAAAAAAUAAACCGUACCGCGCAUAUCCGGUUAAU\n",
            "Time taken for epoch 45 is 7.359073162078857 sec\n",
            "Start epoch 45\n",
            "Time taken for epoch 46 is 7.330380916595459 sec\n",
            "Start epoch 46\n",
            "Time taken for epoch 47 is 7.3500590324401855 sec\n",
            "Start epoch 47\n",
            "Time taken for epoch 48 is 7.33333945274353 sec\n",
            "Start epoch 48\n",
            "Time taken for epoch 49 is 7.292670011520386 sec\n",
            "Start epoch 49\n",
            "UUGAGCAGCAAUGGUGCAGCUAGCCAAUUAAUUGGACCCACACGGGCAUGGAAGGCGCGA\n",
            "UGGCUCAGAAUUAGACCAAGGAUCCACAUGGUAAAAACCCAUCCAUGAUAUAAAACUGGA\n",
            "CAACGUAGAAAGGGAGCUGGGAGACCAACGACUUGUCUGAACCCUGCAUGUCAGACCGCG\n",
            "CCGAGCAGCAACGGUGCACCAUUCCUGAUAUCCAGACUCUUGGAGGCAAGUUAAAUAAGG\n",
            "UUACGCGCCGUGUUUGGAGUAAUUAAAAAAAAUAAACCGUACCGCGCAUAUCCGGUUAAU\n",
            "Time taken for epoch 50 is 7.363312244415283 sec\n",
            "CPU times: user 7min 14s, sys: 35.9 s, total: 7min 50s\n",
            "Wall time: 6min 12s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRWcJDRPd4Ld",
        "colab_type": "code",
        "outputId": "fbc70b71-68f3-4d1b-cf31-7505ea7a95a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "seed = generate_random_vector(240,20)\n",
        "generate_and_save_RNA(generator,1,seed)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CAACGCAACAUGGCUGGAGCUAGGCCGAAGACUAGAUUGAUAGAGGCCUGUCAGGUGCCA\n",
            "GCAUUCAGCACGAGUGCAGUGCUCAUCAUGGAUUGACUGACAGCAGCAUGUCUUCCGAUG\n",
            "UCACAUAGCAAGCUUUCAGUGCUUAAAGUAUCUUAGUCCAUUAUGGCAUGUCUGGUUAGA\n",
            "AAACUCGGCGAUUUUGCAGUAAGUCUAAUGGCUUUACAAACUCGGUCCGAUCUGGUGGCG\n",
            "CGGCUCGGCGAGAUGCCCCUAUAUCUGGUGCCUGUACCCGUCCGACCAUGUCAGGUUGGG\n",
            "UUAAACAUCUAGGUAGAAGCGAGUCUAAUGGCGGGACCCAUCCACGCUUGUCUGGAGCAA\n",
            "UAACGCGCCGUGUCAAAAGCUAGGCAAAUAACUUGCCCGUCAGGAUCAUGUCUGACUCGU\n",
            "CAAAGUGGCAUGGGCGGACUGAUUCUAAUGGCUGGACCGAAACUGUCAUGACUGGCGAUG\n",
            "UUGCGCAACAAGAGAGUCGCUUGCCUAAUAUCUAAACCGGAACGGACAUGUCAGAUGAGU\n",
            "UAACGCAACGUGGGUGAAGUUAUCCAAAUGGAUUGACCGAUCACGGCAUAUCAGGCGAAU\n",
            "AUACGCGACAUGGUACAACUUAGCAAAAAAGCUGGAACCCCUGCAACAAGUCAGGUUAGG\n",
            "UUGCGCACCAAGGGACUCCCAAGACAAAUGCCUAGAUCCUAACCGCCAUGUCAGAUGAGG\n",
            "UGGACCGGAGAGGUUAGCGCAAGGAAAACGUCUGUUCAUAUACGAGCUUGUUAGGUGAGG\n",
            "UAAUGCGUCACGGGUGCCCCGCUACACAUGACAAGACACACAGCAGGAUGUCAUUCGAUG\n",
            "UCGAGCAGCAAGAACGCAGGAAGUAUAAUGACUUGACUCAAACCGGCAUAUCGAAUUAGG\n",
            "UCGCACAAGGCGGGUUGACCGAUCCUAAUGAUUUGACCCAUGCGGUCCUCUCAAAUGAGA\n",
            "GUACAUAACAAGAGUGCAGGGCUUCAUACGGCGUGACGGAACCUGGCCGCGUGGGCGUGA\n",
            "UCAUAUCGGCAGGGAGGAGUGUGUUUAAUACAUGAACAUAUCCGGGCAGGGCUUGCUAGA\n",
            "UGGCUCAACAAGAGUGUAACGCUCCCAAUGUAUUGACCCAUCCUGCCCUGUCAGAUGAGG\n",
            "CUGUGGGGCAAGGGUACACUAAGUCAAAAGGCUAAAAGCUAUCCGGCAUGUUAGGUUGCG\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}